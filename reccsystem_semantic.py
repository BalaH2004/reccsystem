# -*- coding: utf-8 -*-
"""reccsystem-semantic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A7OV8fWgGMSbLz7MVxw00oZmp88kuQyb
"""

!pip install faiss-cpu transformers

import pandas as pd
import faiss
from transformers import AutoTokenizer, AutoModel
import torch
import numpy as np

# Step 1: Load the dataset
file_path = '/content/s.csv'
tweets_df = pd.read_csv(file_path, encoding='ISO-8859-1')
tweets_df = tweets_df[['TweetID', 'Tweet']]

# Step 2: Load the pre-trained language model for embeddings (BERT example)
model_name = 'sentence-transformers/all-MiniLM-L6-v2'
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

# Helper function to get embeddings
def get_embeddings(text):
    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)
    with torch.no_grad():
        outputs = model(**inputs)
    return outputs.last_hidden_state.mean(dim=1).numpy()

# Step 3: Create embeddings for each tweet
tweet_embeddings = []
for tweet in tweets_df['Tweet']:
    embedding = get_embeddings(tweet)
    tweet_embeddings.append(embedding)

# Convert to numpy array for FAISS
tweet_embeddings = np.vstack(tweet_embeddings)

# Step 4: Index embeddings using HNSW-FAISS
d = tweet_embeddings.shape[1]  # Dimensionality of embeddings
index = faiss.IndexHNSWFlat(d, 32)  # HNSW index
index.hnsw.efConstruction = 40
index.add(tweet_embeddings)  # Add the embeddings to the index

# Step 5: Define a function to search similar tweets
def find_similar_tweets(tweet_id, k=6):
    # Get the embedding for the specified tweet
    tweet_index = tweets_df[tweets_df['TweetID'] == tweet_id].index[0]
    tweet_embedding = tweet_embeddings[tweet_index].reshape(1, -1)

    # Search for similar tweets
    distances, indices = index.search(tweet_embedding, k)

    # Create a DataFrame with similar tweets
    similar_tweets_df = pd.DataFrame({
        'TweetID': tweets_df.iloc[indices[0]]['TweetID'].values,
        'Tweet': tweets_df.iloc[indices[0]]['Tweet'].values,
        'Similarity Score': distances[0]
    })

    return similar_tweets_df

# Example: Find similar tweets for a specific tweet_id
similar_tweets_df = find_similar_tweets(100059)
print(similar_tweets_df)